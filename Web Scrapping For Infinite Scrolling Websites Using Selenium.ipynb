{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping For Infinite Scrolling Websites Using Selenium\n",
    "Nowadays many websites involve a feature called [infinite scroll](https://en.wiktionary.org/wiki/infinite_scroll), which essentially automatically expands the current page when scrolling down to show more contents, so that the users don't need to manually click \"next page\" to see the contents. While it is very convenient for the users, it adds difficulty to the web scrapping. In this notebook, I will show the code I developed to automatically scrap infinite scrolling web pages, and demonstrate how to use it using the Sephora Makeup shopping web page as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Python Libraries\n",
    "- **time** (Python built-in library)\n",
    "- **Selenium** (I use the chrome drive for this project. Downloadable from this [site](https://chromedriver.chromium.org/downloads))\n",
    "- **BeautifulSoup** from bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Definition\n",
    "Let's say that my objective is to obtain all of the urls of the products on [Sephora makeup shopping page](https://www.sephora.com/ca/en/beauty/new-makeup?country_switch=ca&lang=en). Through inspecting the page, we understand that the hyperlink for each product is in the a-tag with class \"css-ix8km1\", under the div-tag with class \"css-1s223mm\". The standard procedure would be to find the a-tag with class \"css-ix8km1\" under each div-tags with class \"css-1s223mm\", and extract the hyperlink, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path=r\"E:\\Chromedriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.sephora.com/ca/en/beauty/new-makeup\")\n",
    "urls = []\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "for parent in soup.find_all(class_=\"css-1s223mm\"):\n",
    "    a_tag = parent.find(\"a\", class_=\"css-ix8km1\")\n",
    "    base = \"https://www.sephora.com/\"\n",
    "    link = a_tag.attrs['href']\n",
    "    url = urljoin(base, link)\n",
    "    urls.append(url)\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that we only get 20 urls. This is the number of products shown on the web page before scrolling down. But actually the number should be way more than this! Since when the web page is open by selenium, it is a fresh web page, only five div-tag with class \"css-dkxsdo\" can be found (each \"css-dkxsdo\" tag contains four \"css-1s223mm\" tags). ![image](20items.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we keep scrolling down, new items will show up. This will also be reflected in the html code as we can see more five div-tag with class \"css-dkxsdo\" can be found.![image2](100items.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we need to ask the browser to scroll down the page for us. Until all the html code has shown up, we can get the html code and use BeautifulSoup to obtain the urls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code to scrap infinite scrolling page is as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Web scrapper for infinite scrolling page \n",
    "driver = webdriver.Chrome(executable_path=r\"E:\\Chromedriver\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get(\"https://www.sephora.com/ca/en/beauty/new-makeup\")\n",
    "time.sleep(2)  # Allow 2 seconds for the web page to open\n",
    "scroll_pause_time = 1 # You can set your own pause time. My laptop is a bit slow so I use 1 sec\n",
    "screen_height = driver.execute_script(\"return window.screen.height;\")   # get the screen height of the web\n",
    "i = 1\n",
    "while True:\n",
    "    # scroll one screen height each time\n",
    "    driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "    i += 1\n",
    "    time.sleep(scroll_pause_time)\n",
    "    # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "    scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "    # Break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "    if (screen_height) * i > scroll_height:\n",
    "        break\n",
    "\n",
    "urls = []\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "for parent in soup.find_all(class_=\"css-1s223mm\"):\n",
    "    a_tag = parent.find(\"a\", class_=\"css-ix8km1\")\n",
    "    base = \"https://www.sephora.com/\"\n",
    "    link = a_tag.attrs['href']\n",
    "    url = urljoin(base, link)\n",
    "    urls.append(url)\n",
    "    \n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using this code we can automatically extract all the urls from the page, and the actual number of urls we can get is 135, much larger than 20! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
